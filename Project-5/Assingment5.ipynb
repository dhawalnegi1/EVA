{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assingment5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhawalnegi1/EVA/blob/master/Project-5/Assingment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CMpR05ljdw7",
        "colab_type": "text"
      },
      "source": [
        "Installing the keras library if not already installed and then importing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpN9iEY8j62H",
        "colab_type": "text"
      },
      "source": [
        "Importing the numpy library to be used later, and importing the models and differnt functions of keras library , and the mnist dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3f2V3_4k5lC",
        "colab_type": "text"
      },
      "source": [
        "This cell is for loading the training as well as testing dataset in the specific lists. The dataset is download from and amazon storage bucket and is loaded in the defined variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoeeIqZklfDO",
        "colab_type": "text"
      },
      "source": [
        "The shape (no. of images and size of the image) of the training dataset is printed. We import pyplot package from matplotlib library to plot the image in the notebook. the next line is a magic function .\"%\" is inline magic function used to plot in the notebook instead of creating new window. we are showing the first image fron the 60000 in thetraining dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "eb68a97c-8679-49f3-8db8-40da40096d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f45e229b7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faJOXTgDHl-O",
        "colab_type": "text"
      },
      "source": [
        "In this cell, the test as well as training dataset's shape is modified using reshape function because the dataset loaded was 2 dimensional vector and for convolution we require 3-d vector(i.e height x width of image plus no of channels). In reshape function we are defining no. of input channel as 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLBLnDZkJsRd",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we change the datatype of the dataset to float and then the pixel value of each image in training and testing datasets are normalized(i.e. between 0 & 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVvWIWWtL8QV",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we are printing the classes of 1st 10 images of training dataset,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "5c0c4f5f-25ac-4007-ae53-000f2c3c01c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r74Z-PrTNSF7",
        "colab_type": "text"
      },
      "source": [
        "In, the cell we are coverting the y_train and y_test data into categorical data(i.e for each image there is array of 10 values representing either 0 or 1, telling image belong to which class). Only 1 out of 10 values can be 1. We using numpy to perform this action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WWcMv-SN6L6",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we are printing the categorical value of 1st 10 images of training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "39992eac-8640-4445-8569-8346a4f33d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdctWkasG156",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "03596fb2-139d-44ea-acda-3605271269f8"
      },
      "source": [
        "# example of standardizing a image dataset\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(X_train)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(X_train, Y_train, batch_size=64)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(X_train, Y_train, batch_size=len(X_train), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(X_test)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(X_test, Y_test, batch_size=64)\n",
        "# get a batch\n",
        "testX, testy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(testX.shape, testX.mean(), testX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(X_test, Y_test, batch_size=len(X_test), shuffle=False)\n",
        "# get a batch\n",
        "testX, testy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(testX.shape, testX.mean(), testX.std())\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=0.131 (0.308), test=0.133 (0.310)\n",
            "Data Generator mean=0.131, std=0.308\n",
            "(64, 28, 28, 1) -0.012833156 0.9874655\n",
            "(60000, 28, 28, 1) -4.9324944e-07 0.9999959\n",
            "Data Generator mean=0.133, std=0.310\n",
            "(64, 28, 28, 1) -0.024617376 0.9720879\n",
            "(10000, 28, 28, 1) -2.0761392e-07 0.9999966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzPazoaiOG28",
        "colab_type": "text"
      },
      "source": [
        "This is the cell where are model and its layers are defined. We are defining sequential model.\n",
        "Initial input to the model is (28x28)x1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "c0d7e3a7-45a8-41a4-e70f-a1ac584511b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D, BatchNormalization, Dropout, regularizers\n",
        "\n",
        "model = Sequential() \n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, input_shape=(28,28,1),use_bias=False)) # input=(28x28)      receptive field = 3x3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,use_bias=False,kernel_regularizer=regularizers.l2(0.01)))                        # input=(26x26)     receptive field = 5x5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,use_bias=False,kernel_regularizer=regularizers.l2(0.01)))                       # input=(24x24)     receptive field = 7x7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))                                    # input=(22x22)    receptive field = 14x14\n",
        "model.add(Convolution2D(8,1,use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3,use_bias=False,kernel_regularizer=regularizers.l2(0.01)))                       # input=(11x11)    receptive field = 16x16\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,use_bias=False,kernel_regularizer=regularizers.l2(0.01)))                       # input=(9x9)    receptive field = 18x18\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,use_bias=False,kernel_regularizer=regularizers.l2(0.01)))                      # input=(7x7)    receptive field = 20x20\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 5, 5, activation='relu',use_bias=False))                      # input=(5x5)     receptive field = 22x22\n",
        "model.add(Flatten()) \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), input_shape=(28, 28, 1..., use_bias=False)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, kernel_regularizer=<keras.reg...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, kernel_regularizer=<keras.reg...)`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), use_bias=False, kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         72        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 8)         128       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 8)           576       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 16)          1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4000      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,040\n",
            "Trainable params: 11,864\n",
            "Non-trainable params: 176\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (5, 5), activation=\"relu\", use_bias=False)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNtXNS3rQPbc",
        "colab_type": "text"
      },
      "source": [
        "Here we compile our model and configure its learning process . we pass 3 arguments,i.e. optimizer, loss function and metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "filepath=\"saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "lr=LearningRateScheduler(scheduler, verbose=1)\n",
        "callbacks_list = [checkpoint,lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmqnY0-kQQM0",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we train our model on training dataset , by dividing it into batches of size 512 each. The model is trained 40 times on dataset. i.e. it will go over all images 40 times(epochs) and best model is saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "7af306bd-da99-41a3-aeb3-d329e2a0333a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4202
        }
      },
      "source": [
        "model.fit(batchX, batchy, batch_size=128, epochs=40, verbose=1, validation_data=(testX, testy), callbacks= callbacks_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.3978 - acc: 0.9374 - val_loss: 0.4090 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.88800, saving model to saved.hdf5\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.1240 - acc: 0.9775 - val_loss: 0.1115 - val_acc: 0.9789\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.88800 to 0.97890, saving model to saved.hdf5\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0984 - acc: 0.9822 - val_loss: 0.1129 - val_acc: 0.9761\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.97890\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0895 - acc: 0.9828 - val_loss: 0.1121 - val_acc: 0.9747\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.97890\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0768 - acc: 0.9859 - val_loss: 0.1151 - val_acc: 0.9762\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.97890\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0717 - acc: 0.9869 - val_loss: 0.0767 - val_acc: 0.9841\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.97890 to 0.98410, saving model to saved.hdf5\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0645 - acc: 0.9882 - val_loss: 0.0755 - val_acc: 0.9834\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.98410\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0621 - acc: 0.9884 - val_loss: 0.0541 - val_acc: 0.9908\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.98410 to 0.99080, saving model to saved.hdf5\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0570 - acc: 0.9896 - val_loss: 0.0567 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99080\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0564 - acc: 0.9894 - val_loss: 0.0581 - val_acc: 0.9883\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99080\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0530 - acc: 0.9898 - val_loss: 0.0504 - val_acc: 0.9899\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99080\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0485 - acc: 0.9907 - val_loss: 0.0536 - val_acc: 0.9897\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99080\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0462 - acc: 0.9907 - val_loss: 0.0467 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.99080 to 0.99110, saving model to saved.hdf5\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0456 - acc: 0.9914 - val_loss: 0.0597 - val_acc: 0.9869\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99110\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0435 - acc: 0.9916 - val_loss: 0.0516 - val_acc: 0.9892\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99110\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0431 - acc: 0.9910 - val_loss: 0.0449 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.99110 to 0.99140, saving model to saved.hdf5\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0403 - acc: 0.9918 - val_loss: 0.0435 - val_acc: 0.9904\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99140\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0396 - acc: 0.9925 - val_loss: 0.0412 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.99140 to 0.99180, saving model to saved.hdf5\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0376 - acc: 0.9929 - val_loss: 0.0441 - val_acc: 0.9908\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99180\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0371 - acc: 0.9927 - val_loss: 0.0360 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.99180 to 0.99260, saving model to saved.hdf5\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0345 - acc: 0.9936 - val_loss: 0.0406 - val_acc: 0.9899\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99260\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0344 - acc: 0.9933 - val_loss: 0.0350 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.99260 to 0.99360, saving model to saved.hdf5\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0339 - acc: 0.9933 - val_loss: 0.0368 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99360\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0327 - acc: 0.9932 - val_loss: 0.0368 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99360\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0321 - acc: 0.9938 - val_loss: 0.0367 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99360\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0305 - acc: 0.9939 - val_loss: 0.0327 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99360\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0295 - acc: 0.9942 - val_loss: 0.0438 - val_acc: 0.9901\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99360\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0306 - acc: 0.9937 - val_loss: 0.0348 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99360\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0293 - acc: 0.9945 - val_loss: 0.0385 - val_acc: 0.9916\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99360\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0274 - acc: 0.9951 - val_loss: 0.0348 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99360\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0274 - acc: 0.9945 - val_loss: 0.0398 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.99360\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0282 - acc: 0.9941 - val_loss: 0.0342 - val_acc: 0.9927\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99360\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0269 - acc: 0.9947 - val_loss: 0.0331 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.99360\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0262 - acc: 0.9946 - val_loss: 0.0375 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99360\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0256 - acc: 0.9949 - val_loss: 0.0313 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99360\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0242 - acc: 0.9953 - val_loss: 0.0289 - val_acc: 0.9949\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.99360 to 0.99490, saving model to saved.hdf5\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0243 - acc: 0.9949 - val_loss: 0.0337 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99490\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0242 - acc: 0.9950 - val_loss: 0.0314 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.99490\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.0314 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99490\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0243 - acc: 0.9951 - val_loss: 0.0274 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f462fb6b748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0uLjVLlQRSH",
        "colab_type": "text"
      },
      "source": [
        "In this cell we evaluate our trained model whose output will be accuracy and loss on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('saved.hdf5')\n",
        "score = model.evaluate(testX, testy, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY_80CZcQSDV",
        "colab_type": "text"
      },
      "source": [
        "Print the score calculated in previous cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "outputId": "c00e7980-eebd-4866-d4e8-64b7cca57b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.028852013839781285, 0.9949]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJKjpZ8cQTGw",
        "colab_type": "text"
      },
      "source": [
        "Here we are creating a new list y_pred and initilizing it with prediction values of each test image by our model in categorical form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZcnfb1CQT8u",
        "colab_type": "text"
      },
      "source": [
        "printing the prediction and actual class of first 10 test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "outputId": "0ca8fb2e-89cd-45ae-a58c-6ee5fb6b670b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.1327789e-07 5.5814712e-06 4.6555974e-06 7.4592099e-06 4.1327789e-07\n",
            "  6.5055019e-07 4.1327789e-07 9.9997878e-01 4.1327789e-07 1.2912859e-06]\n",
            " [8.5267320e-06 5.7260957e-02 9.4254297e-01 7.2310731e-06 7.2310731e-06\n",
            "  7.2310731e-06 1.4419481e-04 7.2310731e-06 7.2310731e-06 7.2310731e-06]\n",
            " [1.9205245e-06 9.9949861e-01 1.2694769e-05 1.9205245e-06 1.9205245e-06\n",
            "  5.8782230e-06 1.9205245e-06 4.7123723e-04 1.9205245e-06 1.9205245e-06]\n",
            " [9.9919790e-01 3.0016181e-05 3.0016181e-05 3.0016181e-05 6.5973880e-05\n",
            "  3.4932400e-05 3.9931104e-04 5.5450721e-05 3.0016181e-05 1.2635862e-04]\n",
            " [3.0127787e-06 3.0127787e-06 3.0127787e-06 3.0127787e-06 9.9964404e-01\n",
            "  3.0127787e-06 1.8832327e-05 3.0127787e-06 3.0127787e-06 3.1616801e-04]\n",
            " [1.5915924e-06 9.9897361e-01 6.3354382e-06 1.5915924e-06 1.5915924e-06\n",
            "  1.5915924e-06 1.5915924e-06 1.0088875e-03 1.5915924e-06 1.5915924e-06]\n",
            " [1.0678926e-05 8.0925768e-04 1.0678926e-05 1.0678926e-05 9.9754697e-01\n",
            "  2.0582069e-05 1.0678926e-05 1.0648774e-03 1.4031160e-05 5.0146773e-04]\n",
            " [1.2633842e-04 2.2938146e-04 2.1216563e-04 1.2633842e-04 2.8069327e-03\n",
            "  1.2633842e-04 1.2633842e-04 6.5265072e-04 1.9495070e-04 9.9539858e-01]\n",
            " [4.7418996e-04 2.6408056e-04 2.6408056e-04 2.6408056e-04 2.6408056e-04\n",
            "  8.9322871e-01 1.0360354e-01 2.6408056e-04 4.3584974e-04 9.3744992e-04]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gudmPtdLPCGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10cc6b61-de60-4859-f739-85a030998577"
      },
      "source": [
        "l=[]\n",
        "misclassified = np.nonzero(model.predict_classes(X_test).reshape((-1,)) != y_test)\n",
        "for i in range(25):\n",
        "  l.append(misclassified[0][i])\n",
        "print(l) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[87, 115, 209, 226, 247, 259, 266, 290, 321, 324, 326, 435, 445, 447, 449, 511, 543, 582, 659, 691, 844, 882, 924, 936, 938]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdNDXJ81zg_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "0d4e7cce-fa38-4af5-dd48-bd5d23d45a93"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "for idx in range(25):\n",
        "  v=l[idx]\n",
        "  plt.subplot(5,5,idx+1)\n",
        "  plt.imshow(X_test[v])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYI1GozEI7YA1Go3GILQD1mg0GoP4P3Mr08PfjjGJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTvYfJaX1hew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}