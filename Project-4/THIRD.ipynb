{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "THIRD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhawalnegi1/EVA/blob/master/Project-4/THIRD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# Third network\n",
        "\n",
        "**Improvement added are** \n",
        "1. Dropouts\n",
        "2. Reduced no of kernels to decrease no of parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CMpR05ljdw7",
        "colab_type": "text"
      },
      "source": [
        "Installing the keras library if not already installed and then importing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0af32846-4320-4b5b-f702-0e00c50566c8"
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpN9iEY8j62H",
        "colab_type": "text"
      },
      "source": [
        "Importing the numpy library to be used later, and importing the models and differnt functions of keras library , and the mnist dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3f2V3_4k5lC",
        "colab_type": "text"
      },
      "source": [
        "This cell is for loading the training as well as testing dataset in the specific lists. The dataset is download from and amazon storage bucket and is loaded in the defined variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoeeIqZklfDO",
        "colab_type": "text"
      },
      "source": [
        "The shape (no. of images and size of the image) of the training dataset is printed. We import pyplot package from matplotlib library to plot the image in the notebook. the next line is a magic function .\"%\" is inline magic function used to plot in the notebook instead of creating new window. we are showing the first image fron the 60000 in thetraining dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "bdc9eb3a-e117-452f-8c68-1fa3a013c025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc5908e7160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADoBJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHHYboiL\nHeMEiGlMOjIgLKCiuA5CMiiKiRVFDiFxmuCktK4EdavGrWjlVgmRQynS0ri2I95CAsJ/0CR0FUGi\nwpbFMeYtvJlNY7PsYjZgQ4i9Xp/+sdfRBnaeWc/cmTu75/uRVjtzz71zj6792zszz8x9zN0FIJ53\nFd0AgGIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQU1r5M6mW5vP0KxG7hII5bd6U4f9kE1k\n3ZrCb2YrJG2W1CLpP9x9U2r9GZqls+2iWnYJIKHHuye8btVP+82sRdJNkj4h6QxJq83sjGofD0Bj\n1fKaf6mk5919j7sflnSHpJX5tAWg3moJ/8mSfjXm/t5s2e8xs7Vm1mtmvcM6VMPuAOSp7u/2u3uX\nu5fcvdSqtnrvDsAE1RL+fZLmjbn/wWwZgEmglvA/ImmRmS0ws+mSPi1pRz5tAai3qof63P2Ima2T\n9CONDvVtcfcnc+sMQF3VNM7v7vdJui+nXgA0EB/vBYIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+IKiaZuk1sz5JByWNSDri7qU8mkJ+bFr6n7jl/XPruv9n/np+2drI\nzKPJbU9ZOJisz/yKJesv3zC9bG1n6c7ktvtH3kzWz75rfbJ+6l89nKw3g5rCn/kTd9+fw+MAaCCe\n9gNB1Rp+l/RjM3vUzNbm0RCAxqj1af8yd99nZidJut/MfuHuD45dIfujsFaSZmhmjbsDkJeazvzu\nvi/7PSjpHklLx1mny91L7l5qVVstuwOQo6rDb2azzGz2sduSlkt6Iq/GANRXLU/7OyTdY2bHHuc2\nd/9hLl0BqLuqw+/ueyR9LMdepqyW0xcl697Wmqy/dMF7k/W3zik/Jt3+nvR49U8/lh7vLtJ//WZ2\nsv4v/7YiWe8587aytReH30puu2ng4mT9Az/1ZH0yYKgPCIrwA0ERfiAowg8ERfiBoAg/EFQe3+oL\nb+TCjyfrN2y9KVn/cGv5r55OZcM+kqz//Y2fS9anvZkebjv3rnVla7P3HUlu27Y/PRQ4s7cnWZ8M\nOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8+eg7ZmXkvVHfzsvWf9w60Ce7eRqff85yfqeN9KX\n/t668Ptla68fTY/Td3z7f5L1epr8X9itjDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7o0b0TzR\n2v1su6hh+2sWQ1eem6wfWJG+vHbL7hOS9ce+cuNx93TM9fv/KFl/5IL0OP7Ia68n635u+au7930t\nuakWrH4svQLeoce7dcCH0nOXZzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQFcf5zWyLpEslDbr7\n4mxZu6Q7Jc2X1Cdplbv/utLOoo7zV9Iy933J+sirQ8n6i7eVH6t/8vwtyW2X/vNXk/WTbiruO/U4\nfnmP82+V9PaJ0K+T1O3uiyR1Z/cBTCIVw+/uD0p6+6lnpaRt2e1tki7LuS8AdVbta/4Od+/Pbr8s\nqSOnfgA0SM1v+PnomwZl3zgws7Vm1mtmvcM6VOvuAOSk2vAPmFmnJGW/B8ut6O5d7l5y91Kr2qrc\nHYC8VRv+HZLWZLfXSLo3n3YANErF8JvZ7ZIekvQRM9trZldJ2iTpYjN7TtKfZvcBTCIVr9vv7qvL\nlBiwz8nI/ldr2n74wPSqt/3oZ55K1l+5uSX9AEdHqt43isUn/ICgCD8QFOEHgiL8QFCEHwiK8ANB\nMUX3FHD6tc+WrV15ZnpE9j9P6U7WL/jU1cn67DsfTtbRvDjzA0ERfiAowg8ERfiBoAg/EBThB4Ii\n/EBQjPNPAalpsl/98unJbf9vx1vJ+nXXb0/W/2bV5cm6//w9ZWvz/umh5LZq4PTxEXHmB4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgKk7RnSem6G4+Q58/N1m/9evfSNYXTJtR9b4/un1dsr7olv5k/cie\nvqr3PVXlPUU3gCmI8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2ZbJF0qadDdF2fLNkr6oqRXstU2\nuPt9lXbGOP/k4+ctSdZP3LQ3Wb/9Qz+qet+n/eQLyfpH/qH8dQwkaeS5PVXve7LKe5x/q6QV4yz/\nlrsvyX4qBh9Ac6kYfnd/UNJQA3oB0EC1vOZfZ2a7zWyLmc3JrSMADVFt+G+WtFDSEkn9kr5ZbkUz\nW2tmvWbWO6xDVe4OQN6qCr+7D7j7iLsflXSLpKWJdbvcveTupVa1VdsngJxVFX4z6xxz93JJT+TT\nDoBGqXjpbjO7XdKFkuaa2V5JX5d0oZktkeSS+iR9qY49AqgDvs+PmrR0nJSsv3TFqWVrPdduTm77\nrgpPTD/z4vJk/fVlrybrUxHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3Tpifrv/HD\nyfqlX72m/GPf05PcdrJiqA9ARYQfCIrwA0ERfiAowg8ERfiBoAg/EFTF7/MjtqPL0pfufuFT6Sm6\nFy/pK1urNI5fyY1DZyXrM+/trenxpzrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8U5yVFifr\nz34tPdZ+y3nbkvXzZ6S/U1+LQz6crD88tCD9AEf7c+xm6uHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBVRznN7N5krZL6pDkkrrcfbOZtUu6U9J8SX2SVrn7r+vXalzTFpySrL9w5QfK1jZecUdy20+e\nsL+qnvKwYaCUrD+w+Zxkfc629HX/kTaRM/8RSevd/QxJ50i62szOkHSdpG53XySpO7sPYJKoGH53\n73f3ndntg5KelnSypJWSjn38a5uky+rVJID8HddrfjObL+ksST2SOtz92OcnX9boywIAk8SEw29m\nJ0j6gaRr3P3A2JqPTvg37qR/ZrbWzHrNrHdYh2pqFkB+JhR+M2vVaPBvdfe7s8UDZtaZ1TslDY63\nrbt3uXvJ3UutasujZwA5qBh+MzNJ35H0tLvfMKa0Q9Ka7PYaSffm3x6AepnIV3rPk/RZSY+b2a5s\n2QZJmyR9z8yukvRLSavq0+LkN23+Hybrr/9xZ7J+xT/+MFn/8/fenazX0/r+9HDcQ/9efjivfev/\nJredc5ShvHqqGH53/5mkcvN9X5RvOwAahU/4AUERfiAowg8ERfiBoAg/EBThB4Li0t0TNK3zD8rW\nhrbMSm775QUPJOurZw9U1VMe1u1blqzvvDk9Rffc7z+RrLcfZKy+WXHmB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgwozzH/6z9GWiD//lULK+4dT7ytaWv/vNqnrKy8DIW2Vr5+9Yn9z2tL/7RbLe/lp6\nnP5osopmxpkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IKM87fd1n679yzZ95Vt33f9NrCZH3zA8uT\ndRspd+X0Uadd/2LZ2qKBnuS2I8kqpjLO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl7egWzeZK2\nS+qQ5JK63H2zmW2U9EVJr2SrbnD38l96l3SitfvZxqzeQL30eLcO+FD6gyGZiXzI54ik9e6+08xm\nS3rUzO7Pat9y929U2yiA4lQMv7v3S+rPbh80s6clnVzvxgDU13G95jez+ZLOknTsM6PrzGy3mW0x\nszlltllrZr1m1jusQzU1CyA/Ew6/mZ0g6QeSrnH3A5JulrRQ0hKNPjP45njbuXuXu5fcvdSqthxa\nBpCHCYXfzFo1Gvxb3f1uSXL3AXcfcfejkm6RtLR+bQLIW8Xwm5lJ+o6kp939hjHLO8esdrmk9HSt\nAJrKRN7tP0/SZyU9bma7smUbJK02syUaHf7rk/SlunQIoC4m8m7/zySNN26YHNMH0Nz4hB8QFOEH\ngiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoipfuznVnZq9I+uWY\nRXMl7W9YA8enWXtr1r4keqtWnr2d4u7vn8iKDQ3/O3Zu1uvupcIaSGjW3pq1L4neqlVUbzztB4Ii\n/EBQRYe/q+D9pzRrb83al0Rv1Sqkt0Jf8wMoTtFnfgAFKST8ZrbCzJ4xs+fN7LoieijHzPrM7HEz\n22VmvQX3ssXMBs3siTHL2s3sfjN7Lvs97jRpBfW20cz2Zcdul5ldUlBv88zsJ2b2lJk9aWZ/kS0v\n9Ngl+irkuDX8ab+ZtUh6VtLFkvZKekTSand/qqGNlGFmfZJK7l74mLCZnS/pDUnb3X1xtuxfJQ25\n+6bsD+ccd7+2SXrbKOmNomduziaU6Rw7s7SkyyR9TgUeu0Rfq1TAcSvizL9U0vPuvsfdD0u6Q9LK\nAvpoeu7+oKShty1eKWlbdnubRv/zNFyZ3pqCu/e7+87s9kFJx2aWLvTYJfoqRBHhP1nSr8bc36vm\nmvLbJf3YzB41s7VFNzOOjmzadEl6WVJHkc2Mo+LMzY30tpmlm+bYVTPjdd54w++dlrn7xyV9QtLV\n2dPbpuSjr9maabhmQjM3N8o4M0v/TpHHrtoZr/NWRPj3SZo35v4Hs2VNwd33Zb8HJd2j5pt9eODY\nJKnZ78GC+/mdZpq5ebyZpdUEx66ZZrwuIvyPSFpkZgvMbLqkT0vaUUAf72Bms7I3YmRmsyQtV/PN\nPrxD0prs9hpJ9xbYy+9plpmby80srYKPXdPNeO3uDf+RdIlG3/F/QdLfFtFDmb4+JOmx7OfJonuT\ndLtGnwYOa/S9kaskvU9St6TnJP23pPYm6u27kh6XtFujQessqLdlGn1Kv1vSruznkqKPXaKvQo4b\nn/ADguINPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faJOXTgDHl-O",
        "colab_type": "text"
      },
      "source": [
        "In this cell, the test as well as training dataset's shape is modified using reshape function because the dataset loaded was 2 dimensional vector and for convolution we require 3-d vector(i.e height x width of image plus no of channels). In reshape function we are defining no. of input channel as 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLBLnDZkJsRd",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we change the datatype of the dataset to float and then the pixel value of each image in training and testing datasets are normalized(i.e. between 0 & 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVvWIWWtL8QV",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we are printing the classes of 1st 10 images of training dataset,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "de817716-1701-44b8-97f2-a4a4296b3062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r74Z-PrTNSF7",
        "colab_type": "text"
      },
      "source": [
        "In, the cell we are coverting the y_train and y_test data into categorical data(i.e for each image there is array of 10 values representing either 0 or 1, telling image belong to which class). Only 1 out of 10 values can be 1. We using numpy to perform this action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WWcMv-SN6L6",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we are printing the categorical value of 1st 10 images of training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "a3203519-787d-4b05-b462-c2308d998fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzPazoaiOG28",
        "colab_type": "text"
      },
      "source": [
        "This is the cell where are model and its layers are defined. We are defining sequential model.\n",
        "Initial input to the model is (28x28)x1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "96f51bf0-db5d-45c6-d4dd-1f3a00ade9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D, BatchNormalization, Dropout\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # input=(28x28)      receptive field = 3x3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                        # input=(26x26)     receptive field = 5x5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                       # input=(24x24)     receptive field = 7x7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))                                    # input=(22x22)    receptive field = 14x14\n",
        "model.add(Convolution2D(8,1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu'))                       # input=(11x11)    receptive field = 16x16\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                       # input=(9x9)    receptive field = 18x18\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                      # input=(7x7)    receptive field = 20x20\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 5, 5, activation='relu'))                      # input=(5x5)     receptive field = 22x22\n",
        "model.add(Flatten()) \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 11, 11, 8)         136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 9, 9, 8)           584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 7, 7, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 5, 5, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 5, 5, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 1, 1, 10)          4010      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,138\n",
            "Trainable params: 11,962\n",
            "Non-trainable params: 176\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (5, 5), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNtXNS3rQPbc",
        "colab_type": "text"
      },
      "source": [
        "Here we compile our model and configure its learning process . we pass 3 arguments,i.e. optimizer, loss function and metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmqnY0-kQQM0",
        "colab_type": "text"
      },
      "source": [
        "In this cell, we train our model on training dataset , by dividing it into batches of size 32 each. The model is trained 10 times on dataset. i.e. it will go over all images 10 times(epochs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "66f32b73-2709-471a-ac5a-7c2ab897c8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1,validation_data=(X_test, Y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 30s 496us/step - loss: 0.1870 - acc: 0.9410 - val_loss: 0.0538 - val_acc: 0.9839\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0657 - acc: 0.9792 - val_loss: 0.0380 - val_acc: 0.9877\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 26s 433us/step - loss: 0.0517 - acc: 0.9838 - val_loss: 0.0383 - val_acc: 0.9887\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0450 - acc: 0.9859 - val_loss: 0.0301 - val_acc: 0.9909\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 25s 416us/step - loss: 0.0394 - acc: 0.9876 - val_loss: 0.0324 - val_acc: 0.9903\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 25s 415us/step - loss: 0.0367 - acc: 0.9883 - val_loss: 0.0392 - val_acc: 0.9870\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0347 - acc: 0.9884 - val_loss: 0.0328 - val_acc: 0.9901\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0297 - acc: 0.9904 - val_loss: 0.0306 - val_acc: 0.9910\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.0303 - acc: 0.9900 - val_loss: 0.0322 - val_acc: 0.9907\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0288 - acc: 0.9908 - val_loss: 0.0299 - val_acc: 0.9917\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 25s 421us/step - loss: 0.0265 - acc: 0.9918 - val_loss: 0.0320 - val_acc: 0.9907\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 25s 419us/step - loss: 0.0248 - acc: 0.9915 - val_loss: 0.0278 - val_acc: 0.9925\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0250 - acc: 0.9918 - val_loss: 0.0372 - val_acc: 0.9874\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 26s 438us/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0278 - val_acc: 0.9918\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 25s 421us/step - loss: 0.0223 - acc: 0.9925 - val_loss: 0.0270 - val_acc: 0.9914\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0215 - acc: 0.9933 - val_loss: 0.0268 - val_acc: 0.9918\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 25s 415us/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.0253 - val_acc: 0.9927\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.0206 - acc: 0.9934 - val_loss: 0.0254 - val_acc: 0.9926\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 25s 415us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0281 - val_acc: 0.9922\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 26s 436us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 0.0247 - val_acc: 0.9932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc55fd0f2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0uLjVLlQRSH",
        "colab_type": "text"
      },
      "source": [
        "In this cell we evaluate our trained model whose output will be accuracy and loss on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY_80CZcQSDV",
        "colab_type": "text"
      },
      "source": [
        "Print the score calculated in previous cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "outputId": "805e08e4-5158-4485-d3ac-0453bcee143e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.024671940313173765, 0.9932]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJKjpZ8cQTGw",
        "colab_type": "text"
      },
      "source": [
        "Here we are creating a new list y_pred and initilizing it with prediction values of each test image by our model in categorical form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZcnfb1CQT8u",
        "colab_type": "text"
      },
      "source": [
        "printing the prediction and actual class of first 10 test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "646351b8-51dd-44bf-ff4c-b99dc315f873"
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.5112236e-09 7.5112236e-09 7.5112236e-09 1.8309301e-07 7.5112236e-09\n",
            "  7.5112236e-09 7.5112236e-09 9.9999976e-01 7.5112236e-09 8.1412033e-09]\n",
            " [1.0365495e-09 1.0365495e-09 1.0000000e+00 1.0365495e-09 1.0365495e-09\n",
            "  1.0365495e-09 3.2806369e-08 1.0365495e-09 2.5619737e-09 1.0365495e-09]\n",
            " [2.2692722e-08 9.9999952e-01 2.2692722e-08 2.2692722e-08 2.5485406e-07\n",
            "  7.0152140e-08 2.2692722e-08 2.2692722e-08 1.3983095e-07 2.2692722e-08]\n",
            " [9.9971110e-01 1.0746634e-07 1.0746634e-07 1.0746634e-07 1.0746634e-07\n",
            "  1.0746634e-07 2.8760405e-04 1.0746634e-07 1.0746634e-07 4.9151328e-07]\n",
            " [3.5747298e-09 3.5747298e-09 3.5747298e-09 3.5747298e-09 9.9999702e-01\n",
            "  3.5747298e-09 6.9391786e-09 3.5747298e-09 3.5747298e-09 3.0025280e-06]\n",
            " [5.4476168e-08 9.9999762e-01 5.4476168e-08 5.4476168e-08 1.2852092e-06\n",
            "  5.4476168e-08 5.4476168e-08 6.2616472e-08 7.4050962e-07 5.4476168e-08]\n",
            " [1.7073848e-08 1.7073848e-08 1.7073848e-08 1.7073848e-08 9.9999952e-01\n",
            "  1.7073848e-08 1.7073848e-08 7.9896523e-08 1.7574058e-07 6.2743560e-08]\n",
            " [1.9551390e-08 1.9551390e-08 1.9551390e-08 2.9788721e-08 5.3770764e-06\n",
            "  2.6422821e-08 1.9551390e-08 1.9551390e-08 3.5867708e-07 9.9999416e-01]\n",
            " [3.1733583e-07 3.1733583e-07 3.1733583e-07 3.1733583e-07 3.1733583e-07\n",
            "  9.9983525e-01 1.6192981e-04 3.1733583e-07 4.7227195e-07 3.1733583e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl08-nficVvj",
        "colab_type": "text"
      },
      "source": [
        "The parameter are well under 15k and dropout used are little high. we can remove dropout from few layer. Further we can play with batch size and learning rate to achieve the target accuracy and can remove bias from eacgh layer to further reduce no of parameter."
      ]
    }
  ]
}